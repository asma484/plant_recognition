{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree model for Plant Disease Data\n",
    "\n",
    "In this notebook, we will apply the Decision Tree model to a dataset of plant diseases. The dataset is retrieved from Kaggle (see for: [Plant Disease Dataset](https://www.kaggle.com/datasets/saroz014/plant-disease).\n",
    "The notebook is organized in the following structure: \n",
    "+  1. Importing necessary libraries for preprocessing and training the model\n",
    "+  2. Setting paths to the plant-disease dataset\n",
    "+  3. Defining a function to load images into a DataFrame for further processing\n",
    "+  4. Checking for duplicate entries as part of preprocessing\n",
    "+  5. Balancing 'healthy' and 'unhealthy' images, as both classes are highly imbalanced\n",
    "+  6. Defining a function to resize, normalize, and flatten images in batches for more efficient training and better performance\n",
    "+  7. Creating DataFrame of batches to handle large datasets efficiently and separating variables into feature and label variables\n",
    "+  8. Applying PCA transformation to the data to enhance model performance by focusing on the most significant features\n",
    "+  9. Training the Decision Tree Model\n",
    "+ 10. Generating a classification report for all classes (subfolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Import necessary libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import shutil\n",
    "from sklearn.utils import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setting paths to plant-disease dataset\n",
    "Sets the paths to the dataset directories and converts them to absolute paths. Prints the current working directory and the absolute paths for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current path: c:\\Program Files (x86)\\Projects\\Plants\\june24_bds_int_plant_reco\\notebooks\n",
      "Absolute training path: c:\\Program Files (x86)\\Projects\\Plants\\june24_bds_int_plant_reco\\notebooks\\src\\data\\plant-disease\\dataset\\train\n",
      "Absolute test path: c:\\Program Files (x86)\\Projects\\Plants\\june24_bds_int_plant_reco\\notebooks\\src\\data\\plant-disease\\dataset\\test\n"
     ]
    }
   ],
   "source": [
    "# dataset directories\n",
    "script_dir = os.getcwd()\n",
    "train_path = os.path.join(script_dir, \"src\", \"data\", \"plant-disease\", \"dataset\", \"train\")\n",
    "test_path = os.path.join(script_dir, \"src\", \"data\", \"plant-disease\", \"dataset\", \"test\")\n",
    "\n",
    "# converting to absolute paths\n",
    "absolut_train = os.path.abspath(train_path)\n",
    "absolut_test = os.path.abspath(test_path)\n",
    "\n",
    "# Ensuring that paths exist\n",
    "print(\"Current path:\", script_dir)\n",
    "print(\"Absolute training path:\", absolut_train)\n",
    "print(\"Absolute test path:\", absolut_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Function to load images into a Dataframe\n",
    "Walks through the directory structure, loads image paths and their labels into lists, then creates and returns a DataFrame containing these lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame Shape: (43455, 2)\n",
      "Valid DataFrame Shape: (10849, 2)\n"
     ]
    }
   ],
   "source": [
    "# Function that loads images and creates a DataFrame with the two columns 'image_path' and 'label'\n",
    "def load_images(folder):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for subdir, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.jpg') or file.endswith('.JPG') or file.endswith('.png'):\n",
    "                label = os.path.basename(subdir)\n",
    "                img_path = os.path.join(subdir, file)\n",
    "                image_paths.append(img_path)\n",
    "                labels.append(label)\n",
    "    return pd.DataFrame({'image_path': image_paths, 'label': labels})\n",
    "\n",
    "# Resulting DataFrames\n",
    "images_train = load_images(absolut_train)\n",
    "images_test = load_images(absolut_test)\n",
    "\n",
    "# Basic Analysis\n",
    "print(\"Train DataFrame Shape:\", images_train.shape)\n",
    "print(\"Valid DataFrame Shape:\", images_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Check for duplicate entries\n",
    "Identifies and prints duplicate image paths in the DataFrame. Ensures there are no duplicate entries before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking train dataset for duplicates...\n",
      "Duplicate entries: 0\n",
      "Checking valid dataset for duplicates...\n",
      "Duplicate entries: 0\n"
     ]
    }
   ],
   "source": [
    "# Function for checking duplicate entries in 'image_path' column\n",
    "def check_duplicates(df):\n",
    "    duplicates = df[df.duplicated(subset=['image_path'])]\n",
    "    print(f\"Duplicate entries: {len(duplicates)}\")\n",
    "    return duplicates\n",
    "\n",
    "# Check train dataset\n",
    "print(\"Checking train dataset for duplicates...\")\n",
    "duplicate_train_images = check_duplicates(images_train)\n",
    "\n",
    "# Check valid dataset\n",
    "print(\"Checking valid dataset for duplicates...\")\n",
    "duplicate_valid_images = check_duplicates(images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Balancing 'healthy' and 'unhealthy' Images\n",
    "The dataset is imbalanced, with more \"unhealthy\" images than \"healthy.\" To address this, we add a target column labeling images as 'healthy' or 'unhealthy' and balance the training data by downsampling the majority class ('unhealthy') to match the number of 'healthy' samples. This ensures fair model training and prevents bias towards the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "unhealthy    31384\n",
      "healthy      12071\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n",
      "target\n",
      "unhealthy    7836\n",
      "healthy      3013\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "unhealthy    12071\n",
      "healthy      12071\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Creating new target column labeling images as healthy or unhealthy\n",
    "images_train['target'] = images_train['label'].apply(lambda x: 'healthy' if 'healthy' in x.lower() else 'unhealthy')\n",
    "images_test['target'] = images_test['label'].apply(lambda x: 'healthy' if 'healthy' in x.lower() else 'unhealthy')\n",
    "\n",
    "print(images_train.target.value_counts())\n",
    "print(\"\\n\")\n",
    "print(images_test.target.value_counts())\n",
    "\n",
    "# Separate majority and minority classes which are highly unbalanced\n",
    "df_majority_train = images_train[images_train.target == 'unhealthy']\n",
    "df_minority_train = images_train[images_train.target == 'healthy']\n",
    "\n",
    "# Downsample majority class of training data\n",
    "df_majority_train_downsampled = resample(df_majority_train,\n",
    "                                   replace=False,                       # sample without replacement\n",
    "                                   n_samples=len(df_minority_train),    # to match minority class\n",
    "                                   random_state=13)                     # reproducible results\n",
    "\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled_train = pd.concat([df_majority_train_downsampled, df_minority_train])\n",
    "\n",
    "# Display new class counts\n",
    "print(df_downsampled_train.target.value_counts())\n",
    "\n",
    "# Reassign the downsampled DataFrames to the original variables\n",
    "images_train = df_downsampled_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Function to resize, normalize and flatten images in batches\n",
    "Reads an image from the given path, resizes it to 64x64 pixels, normalizes pixel values to [0, 1] and flattens the image array in batches for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to resize and normalize pixel values\n",
    "def read_and_normalize_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is not None:\n",
    "        img = cv2.resize(img, (64, 64))                # Resize to 64x64 pixels\n",
    "        img = img / 255.0                              # Normalize the image\n",
    "    return img\n",
    "\n",
    "# Function to flatten array and process images in batches\n",
    "def flatten_dataset_in_batches(df, batch_size=32):\n",
    "    total_images = len(df)\n",
    "    for start in range(0, total_images, batch_size):\n",
    "        end = min(start + batch_size, total_images)\n",
    "        batch_df = df.iloc[start:end]\n",
    "\n",
    "        flatten_images = []\n",
    "        for img_path in batch_df['image_path']:\n",
    "            img = read_and_normalize_image(img_path)\n",
    "            if img is not None:\n",
    "                flatten_images.append(img.flatten())    # Flatten the image\n",
    "\n",
    "        flattened_images_df = pd.DataFrame(np.array(flatten_images))\n",
    "        flattened_images_df['label'] = batch_df['label'].values\n",
    "\n",
    "        yield flattened_images_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Creating DataFrame of batches and separating variables to feature and label variables\n",
    "Processes images in batches and combines them into a single DataFrame. Encodes the labels and separates features (flattened images) from target variables (encoded labels)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (24142, 12288)\n",
      "y_train shape: (24142,)\n",
      "X_test shape: (10849, 12288)\n",
      "y_test shape: (10849,)\n"
     ]
    }
   ],
   "source": [
    "# Concatenating all batches into a single DataFrame\n",
    "def create_dataframe_from_batches(df, batch_size=32):\n",
    "    all_batches = []\n",
    "    for batch_df in flatten_dataset_in_batches(df, batch_size=batch_size):\n",
    "        all_batches.append(batch_df)\n",
    "\n",
    "    full_df = pd.concat(all_batches, ignore_index=True)\n",
    "\n",
    "    return full_df\n",
    "\n",
    "train_df = create_dataframe_from_batches(images_train)\n",
    "test_df = create_dataframe_from_batches(images_test)\n",
    "\n",
    "\n",
    "# Initialize LabelEncoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform target variable of training\n",
    "train_df['label_encoded'] = le.fit_transform(train_df['label'])\n",
    "\n",
    "# transform target variable of test\n",
    "test_df['label_encoded'] = le.transform(test_df['label'])\n",
    "\n",
    "# Separation of features und target variables\n",
    "X_train = train_df.drop(columns=['label', 'label_encoded']).values\n",
    "y_train = train_df['label_encoded'].values\n",
    "X_test = test_df.drop(columns=['label', 'label_encoded']).values\n",
    "y_test = test_df['label_encoded'].values\n",
    "\n",
    "# Checking dimension of data\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Applying PCA transformation onto data\n",
    "Fits PCA to the training data to determine the number of principal components required to retain 95% of the variance, then applies this PCA transformation to both the training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 95% variance: 1340\n"
     ]
    }
   ],
   "source": [
    "# 8.1. Fit PCA on the flattened training data\n",
    "pca = PCA().fit(X_train)\n",
    "\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of components for 95% variance: {n_components_95}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2. Apply PCA transformation with the number of components that explain 95% variance\n",
    "pca = PCA(n_components=n_components_95)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Training Decision Tree Model\n",
    "Trains a Decision Tree Classifier on the PCA-transformed training data. Makes predictions on the PCA-transformed test data. Evaluates the modelâ€™s performance and prints accuracy and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 36.81%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       126\n",
      "           1       0.00      0.00      0.00       124\n",
      "           2       0.00      0.00      0.00        55\n",
      "           3       0.33      0.42      0.37       329\n",
      "           4       0.48      0.54      0.51       300\n",
      "           5       0.00      0.00      0.00       210\n",
      "           6       0.37      0.28      0.32       170\n",
      "           7       0.00      0.00      0.00       102\n",
      "           8       0.86      0.72      0.78       238\n",
      "           9       0.00      0.00      0.00       197\n",
      "          10       0.83      0.81      0.82       232\n",
      "          11       0.00      0.00      0.00       236\n",
      "          12       0.00      0.00      0.00       276\n",
      "          13       0.37      0.32      0.34       215\n",
      "          14       0.00      0.00      0.00        84\n",
      "          15       0.52      0.81      0.63      1101\n",
      "          16       0.54      0.23      0.32       459\n",
      "          17       0.38      0.08      0.14        72\n",
      "          18       0.00      0.00      0.00       199\n",
      "          19       0.06      0.30      0.09       295\n",
      "          20       0.28      0.21      0.24       200\n",
      "          21       0.00      0.00      0.00       200\n",
      "          22       0.00      0.00      0.00        30\n",
      "          23       0.00      0.00      0.00        74\n",
      "          24       0.58      0.76      0.66      1018\n",
      "          25       0.19      0.60      0.28       367\n",
      "          26       0.38      0.27      0.31       221\n",
      "          27       0.28      0.21      0.24        91\n",
      "          28       0.30      0.22      0.25       425\n",
      "          29       0.00      0.00      0.00       200\n",
      "          30       1.00      0.03      0.05       381\n",
      "          31       0.00      0.00      0.00       190\n",
      "          32       0.00      0.00      0.00       354\n",
      "          33       0.00      0.00      0.00       335\n",
      "          34       0.00      0.00      0.00       280\n",
      "          35       0.50      0.64      0.56      1071\n",
      "          36       0.00      0.00      0.00        74\n",
      "          37       0.18      0.71      0.28       318\n",
      "\n",
      "    accuracy                           0.37     10849\n",
      "   macro avg       0.22      0.21      0.19     10849\n",
      "weighted avg       0.33      0.37      0.31     10849\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\janze\\anaconda3\\envs\\plantenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\janze\\anaconda3\\envs\\plantenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\janze\\anaconda3\\envs\\plantenv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Setting and training Decision Tree Model\n",
    "dt = DecisionTreeClassifier(max_depth=6, random_state=13)\n",
    "dt.fit(X_train_pca, y_train)\n",
    "\n",
    "# Prediction of model\n",
    "y_pred = dt.predict(X_test_pca)\n",
    "\n",
    "# Evaluating model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Generate the classification report for all classes (subfolders)\n",
    "Generates a detailed classification report showing precision, recall, and F1-score for each class. Prints the full report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Classification Report for all classes:\n",
      "\n",
      "                                                    precision    recall  f1-score   support\n",
      "\n",
      "                                Apple___Apple_scab       0.00      0.00      0.00       126\n",
      "                                 Apple___Black_rot       0.00      0.00      0.00       124\n",
      "                          Apple___Cedar_apple_rust       0.00      0.00      0.00        55\n",
      "                                   Apple___healthy       0.33      0.42      0.37       329\n",
      "                               Blueberry___healthy       0.48      0.54      0.51       300\n",
      "          Cherry_(including_sour)___Powdery_mildew       0.00      0.00      0.00       210\n",
      "                 Cherry_(including_sour)___healthy       0.37      0.28      0.32       170\n",
      "Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot       0.00      0.00      0.00       102\n",
      "                       Corn_(maize)___Common_rust_       0.86      0.72      0.78       238\n",
      "               Corn_(maize)___Northern_Leaf_Blight       0.00      0.00      0.00       197\n",
      "                            Corn_(maize)___healthy       0.83      0.81      0.82       232\n",
      "                                 Grape___Black_rot       0.00      0.00      0.00       236\n",
      "                      Grape___Esca_(Black_Measles)       0.00      0.00      0.00       276\n",
      "        Grape___Leaf_blight_(Isariopsis_Leaf_Spot)       0.37      0.32      0.34       215\n",
      "                                   Grape___healthy       0.00      0.00      0.00        84\n",
      "          Orange___Haunglongbing_(Citrus_greening)       0.52      0.81      0.63      1101\n",
      "                            Peach___Bacterial_spot       0.54      0.23      0.32       459\n",
      "                                   Peach___healthy       0.38      0.08      0.14        72\n",
      "                     Pepper,_bell___Bacterial_spot       0.00      0.00      0.00       199\n",
      "                            Pepper,_bell___healthy       0.06      0.30      0.09       295\n",
      "                             Potato___Early_blight       0.28      0.21      0.24       200\n",
      "                              Potato___Late_blight       0.00      0.00      0.00       200\n",
      "                                  Potato___healthy       0.00      0.00      0.00        30\n",
      "                               Raspberry___healthy       0.00      0.00      0.00        74\n",
      "                                 Soybean___healthy       0.58      0.76      0.66      1018\n",
      "                           Squash___Powdery_mildew       0.19      0.60      0.28       367\n",
      "                          Strawberry___Leaf_scorch       0.38      0.27      0.31       221\n",
      "                              Strawberry___healthy       0.28      0.21      0.24        91\n",
      "                           Tomato___Bacterial_spot       0.30      0.22      0.25       425\n",
      "                             Tomato___Early_blight       0.00      0.00      0.00       200\n",
      "                              Tomato___Late_blight       1.00      0.03      0.05       381\n",
      "                                Tomato___Leaf_Mold       0.00      0.00      0.00       190\n",
      "                       Tomato___Septoria_leaf_spot       0.00      0.00      0.00       354\n",
      "     Tomato___Spider_mites Two-spotted_spider_mite       0.00      0.00      0.00       335\n",
      "                              Tomato___Target_Spot       0.00      0.00      0.00       280\n",
      "            Tomato___Tomato_Yellow_Leaf_Curl_Virus       0.50      0.64      0.56      1071\n",
      "                      Tomato___Tomato_mosaic_virus       0.00      0.00      0.00        74\n",
      "                                  Tomato___healthy       0.18      0.71      0.28       318\n",
      "\n",
      "                                          accuracy                           0.37     10849\n",
      "                                         macro avg       0.22      0.21      0.19     10849\n",
      "                                      weighted avg       0.33      0.37      0.31     10849\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Full classification report\n",
    "full_classification_report = classification_report(\n",
    "    y_test, \n",
    "    y_pred, \n",
    "    target_names=le.classes_,  # Consider all classes\n",
    "    zero_division=0            # Avoid errors for divisions by zero\n",
    ")\n",
    "\n",
    "# Print the full classification report for all classes\n",
    "print(\"Full Classification Report for all classes:\\n\")\n",
    "print(full_classification_report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plantenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
